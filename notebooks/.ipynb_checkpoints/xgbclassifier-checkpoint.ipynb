{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.impute import SimpleImputer\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.preprocessing import RobustScaler  \n",
    "from xgboost import XGBClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_raw_data(operating_system ='mac'):\n",
    "    '''generate a dictionary of raw dataframes\n",
    "    \n",
    "    parameters\n",
    "    -----------\n",
    "    type of operating system used windows or mac\n",
    "    default mac\n",
    "    \n",
    "    '''\n",
    "    if operating_system == 'mac':\n",
    "        base_file_path = r\"/Users/{}/Desktop/data\".format(os.getlogin())\n",
    "    if operating_system == 'windows':\n",
    "        base_file_path = r\"C:\\Users\\{}\\Desktop\\data\".format(os.getlogin())\n",
    "    df_dict = dict()\n",
    "    for file in os.listdir(base_file_path):\n",
    "        if file.endswith('.csv'):\n",
    "            df_dict[file.split('.')[0]] = pd.read_csv(os.path.join(base_file_path,file))\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = import_raw_data()\n",
    "df = df_dict.get('winemag-data-130k-v2').copy()\n",
    "temp_df = df_dict.get('temperature').copy()\n",
    "country_iso = df_dict.get('country_iso_data').copy()\n",
    "weather_month_v2 = df_dict.get('weather_country_month_v2').copy()\n",
    "features = df_dict.get('data_test').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='test', ylabel='count'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# changed from using original quantile list, big factor in driving results \n",
    "df['test'] = pd.cut(df['points'],bins=5,labels=[1,2,3,4,5])\n",
    "df['test'].value_counts()\n",
    "sns.countplot(x='test', color='darkgreen',\n",
    "                  data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**columns to remove**\n",
    "\n",
    "description, designation & Twitter handle removed at this stage, explore later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_DROP = ['Unnamed: 0','designation','region_2','taster_twitter_handle','points']\n",
    "df.drop(columns=COLUMN_DROP,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dealing with missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['variety','province','country','taster_name','region_1'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        0\n",
       "description    0\n",
       "price          0\n",
       "province       0\n",
       "region_1       0\n",
       "taster_name    0\n",
       "title          0\n",
       "variety        0\n",
       "winery         0\n",
       "test           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_median = SimpleImputer(strategy='median')\n",
    "df['price'] = imp_median.fit_transform(df[['price']])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['description','title'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing  & Feature Engineering\n",
    "\n",
    "extracting year from text and cleaing reuslt to produce valid year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## year \n",
    "count_year = df[df['title'].str.contains('\\d',regex=True)].shape[0]\n",
    "df['number_extract'] = df['title'].str.extract('(\\d+)')\n",
    "df['number_extract'] = np.where(len(df['number_extract'])<4 & len(df['number_extract'])<=5,np.nan,df['number_extract'])\n",
    "df['number_extract'] = pd.to_numeric(df['number_extract'])\n",
    "df['number_extract'] = np.where(\n",
    "                    (df['number_extract']>=2021) | (df['number_extract']<=(2021-70)),\n",
    "                    np.nan,\n",
    "                    df['number_extract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding simple imputer but may need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        0\n",
       "description    0\n",
       "price          0\n",
       "province       0\n",
       "region_1       0\n",
       "taster_name    0\n",
       "title          0\n",
       "variety        0\n",
       "winery         0\n",
       "test           0\n",
       "year           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_median = SimpleImputer(strategy='median')\n",
    "df['number_extract'] = imp_median.fit_transform(df[['number_extract']])\n",
    "df['number_extract'] = pd.to_datetime(df['number_extract'],format='%Y').dt.year \n",
    "df.rename(columns={'number_extract':'year'},inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating length of the name to work out whether name longer names and titles relate to better reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['title','taster_name']:\n",
    "     df[f\"{col}_length\"] = df[col].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO change labels to numbers\n",
    "df['price_bin'] = pd.cut(df['price'],bins=15,labels=False)\n",
    "df.drop(columns=['taster_name', 'title'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Weather Data\n",
    "\n",
    "additional feature related to average temperature for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_feature = df.set_index('country').join(country_iso.set_index('country'))\n",
    "weather_iso_df = weather_month_v2.set_index('country').join(country_iso.set_index('country'))\n",
    "weather_iso_df['year'] = pd.to_datetime(weather_iso_df['month']).dt.year\n",
    "weather_iso_summary_df = weather_iso_df.groupby(['country_iso', 'year'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "              weather_feature, \n",
    "              weather_iso_summary_df,  \n",
    "              how='left', \n",
    "              left_on=['country_iso','year'], \n",
    "              right_on=['country_iso','year']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description           0\n",
       "price                 0\n",
       "province              0\n",
       "region_1              0\n",
       "variety               0\n",
       "winery                0\n",
       "test                  0\n",
       "year                  0\n",
       "title_length          0\n",
       "taster_name_length    0\n",
       "price_bin             0\n",
       "country_iso           0\n",
       "avg_temp              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_median = SimpleImputer(strategy='median')\n",
    "df['avg_temp'] = imp_median.fit_transform(df[['avg_temp']])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_richness(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    return unique_word_length/total_length\n",
    "\n",
    "df['vocab richness'] = df['description'].apply(vocab_richness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/edwardburroughes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import string \n",
    "punc = set(string.punctuation)\n",
    "\n",
    "#loading stop_words\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# creating a set of stop words\n",
    "stop_words = [set(stopwords.words('english'))]\n",
    "\n",
    "# combining the 2 sets with an \"or\" operator (i.e. \"|\")\n",
    "all_stops = stop_words | punc\n",
    "\n",
    "# loop to pre-process data\n",
    "clean_desc =[]\n",
    "for item in df['description'].to_list():\n",
    "    tok_desc = word_tokenize(item)\n",
    "    lower_data = [i.lower() for i in tok_desc]\n",
    "    tok_desc_no_num = [i for i in lower_data if i.isalpha()]\n",
    "    filtered_desc = [i for i in tok_desc_no_num if i not in all_stops]\n",
    "    clean_desc.append(filtered_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing the data in a new dataframe\n",
    "clean_desc_untok = [' '.join(i) for i in clean_desc]\n",
    "column_names = ['original_desc', 'untok_description']\n",
    "data_tuple= list(zip(df['description'], clean_desc_untok))\n",
    "desc_df = pd.DataFrame(data_tuple, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/edwardburroughes/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('movie_reviews')\n",
    "tb = Blobber(analyzer=NaiveBayesAnalyzer())\n",
    "blob = [tb(text) for text in desc_df['untok_description']]\n",
    "sentiment_values = [text.sentiment for text in blob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>0.0774711</td>\n",
       "      <td>0.922529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.835127</td>\n",
       "      <td>0.164873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.995154</td>\n",
       "      <td>0.00484628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>0.0718264</td>\n",
       "      <td>0.928174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.947882</td>\n",
       "      <td>0.0521175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clf        pos         neg\n",
       "0  neg  0.0774711    0.922529\n",
       "1  pos   0.835127    0.164873\n",
       "2  pos   0.995154  0.00484628\n",
       "3  neg  0.0718264    0.928174\n",
       "4  pos   0.947882   0.0521175"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.DataFrame(zip(*sentiment_values)).T\n",
    "stats.columns = ['clf','pos','neg']\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(stats['clf'])\n",
    "df = df.join(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move back onto original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['test','description','clf'])\n",
    "y = df[['test']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Feature selection defining best & worst features for one hot encoded categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1(model,X_test,y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_test,y_pred,average='weighted')\n",
    "    return score\n",
    "\n",
    "def create_dummies_ohe(X,cat_columns):\n",
    "    categorical_x = pd.get_dummies(X[cat_columns],prefix=['1','2','3','4','5'])\n",
    "    numeric_cols = list(set(X.columns)-set(cat_columns))\n",
    "    return pd.concat([X[numeric_cols],categorical_x], axis=1)\n",
    "\n",
    "def create_dummies_le(X,cat_columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in cat_columns:\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout method on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the features selected above\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "numeric_features = ['price','title_length','taster_name_length','avg_temp','year','pos','neg','vocab richness']\n",
    "cat_features = ['province','variety','country_iso','price_bin','winery','region_1']\n",
    "\n",
    "def select_cat_data_threshold(X,feature_data,threshold_value,cat_features=cat_features):\n",
    "    dictionary_filter = {cat:feature_data.loc[(feature_data[cat]==True) & \n",
    "                                              (feature_data['scores']<=threshold_value),'features']for cat in cat_features}\n",
    "    for cat,series in dictionary_filter.items():\n",
    "        X.loc[X[cat].isin(series),cat] = 'Other'\n",
    "    return (X,dictionary_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test whether the model speed and F1 given the threshold defined above and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6046468845223799\n",
      "0:11:45.482548\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "X,features_replace = select_cat_data_threshold(X,features,1E-6)\n",
    "X = create_dummies_ohe(X,cat_features)\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "sc = QuantileTransformer()\n",
    "X_train[numeric_features] = sc.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = sc.fit_transform(X_test[numeric_features])\n",
    "rf_classifier = RandomForestClassifier(n_estimators=500,n_jobs=-1)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(f1_score(y_test,y_pred,average='weighted'))\n",
    "end = datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "# X,features_replace = select_cat_data_threshold(X,features,1E-6)\n",
    "# X = create_dummies_ohe(X,cat_features)\n",
    "# X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "# sc = QuantileTransformer()\n",
    "# X_train[numeric_features] = sc.fit_transform(X_train[numeric_features])\n",
    "# X_test[numeric_features] = sc.fit_transform(X_test[numeric_features])\n",
    "print('start model')\n",
    "xgb_classifier = OneVsRestClassifier(XGBClassifier(n_jobs=-1, max_depth=7, n_estimators=200))\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "print(f1_score(y_test,y_pred,average='weighted'))\n",
    "end = datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using F1-score as imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using xgboost is almost is definitely better still very low lets amend the imbalances in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE,BorderlineSMOTE,SVMSMOTE\n",
    "from sklearn import neighbors\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "over = SMOTE()\n",
    "under = RandomUnderSampler()\n",
    "steps = [('o', over), ('u', under)]\n",
    "smote_pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversample = BorderlineSMOTE(sampling_strategy='minority',k_neighbors=1,m_neighbors=1)\n",
    "X_train_resample,y_train_resample = over.fit_resample(X_train,y_train)\n",
    "xgb_classifier.fit(X_train_resample,y_train_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5953507613327068"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(xgb_classifier,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smote perhaps a more focused sampling strategy is required for balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('o',\n",
       "                                        BorderlineSMOTE(k_neighbors=1,\n",
       "                                                        m_neighbors=1,\n",
       "                                                        sampling_strategy='minority')),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'o__k_neighbors': [1, 5], 'o__m_neighbors': [1, 20],\n",
       "                         'o__sampling_strategy': ('minority', 'not majority',\n",
       "                                                  'all')},\n",
       "             scoring='f1_weighted', verbose=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline = Pipeline([('o', oversample),\n",
    "           ('xgb', OneVsRestClassifier(XGBClassifier(n_jobs=-1, max_depth=7, n_estimators=200)))])\n",
    "parameters = {'o__sampling_strategy':('minority','not majority','all'),\n",
    "             'o__k_neighbors':[1,5],\n",
    "             'o__m_neighbors':[1,20]}\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, \n",
    "                           verbose=5, scoring = \"f1_weighted\", \n",
    "                           refit=True, cv=5)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o__k_neighbors': 1, 'o__m_neighbors': 20, 'o__sampling_strategy': 'minority'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {\"learning_rate\":[0.05,0.1,0.15,0.2,0.25,0.3,0.35],\n",
    "          \"max_depth\":[3,4,5,6,8,10,12,15,17],\n",
    "          \"min_child_weight\":[1,3,5,7,9,11],\n",
    "          \"gamma\":[0.0,0.1,0.3,0.4,0.5,0.6],\n",
    "          \"colsample_bytree\":[0.3,0.4,0.5,0.7,0.8,0.9],\n",
    "          \"n_estimators\":range(60, 220, 40)\n",
    "         }\n",
    "xgb_random_search = RandomizedSearchCV(xgb_classifier,\n",
    "                                       param_distributions=params,\n",
    "                                       cv=5,\n",
    "                                       scoring='f1_weighted',\n",
    "                                       verbose=3,\n",
    "                                       n_iter = 10,\n",
    "                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=15, min_child_weight=1, n_estimators=180; total time=  35.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=15, min_child_weight=1, n_estimators=180; total time=  37.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=15, min_child_weight=1, n_estimators=180; total time=  37.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=15, min_child_weight=1, n_estimators=180; total time=  40.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=15, min_child_weight=1, n_estimators=180; total time=  37.4s\n",
      "[CV 1/5] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=6, min_child_weight=3, n_estimators=60; total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=6, min_child_weight=3, n_estimators=60; total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=6, min_child_weight=3, n_estimators=60; total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=6, min_child_weight=3, n_estimators=60; total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=6, min_child_weight=3, n_estimators=60; total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=60; total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=60; total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=60; total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=60; total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=60; total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=8, min_child_weight=7, n_estimators=180; total time=  20.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=8, min_child_weight=7, n_estimators=180; total time=  21.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=8, min_child_weight=7, n_estimators=180; total time=  21.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=8, min_child_weight=7, n_estimators=180; total time=  20.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=8, min_child_weight=7, n_estimators=180; total time=  20.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, min_child_weight=9, n_estimators=100; total time=  18.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, min_child_weight=9, n_estimators=100; total time=  19.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, min_child_weight=9, n_estimators=100; total time=  18.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, min_child_weight=9, n_estimators=100; total time=  18.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, min_child_weight=9, n_estimators=100; total time=  18.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=180; total time=  16.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=180; total time=  17.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=180; total time=  16.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=180; total time=  16.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=180; total time=  16.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.6, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100; total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.6, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100; total time=   3.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.6, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100; total time=   4.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.6, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100; total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.6, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100; total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.15, max_depth=17, min_child_weight=7, n_estimators=180; total time=  44.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.15, max_depth=17, min_child_weight=7, n_estimators=180; total time=  45.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.15, max_depth=17, min_child_weight=7, n_estimators=180; total time=  43.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.15, max_depth=17, min_child_weight=7, n_estimators=180; total time=  43.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.15, max_depth=17, min_child_weight=7, n_estimators=180; total time=  45.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=60; total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=60; total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=60; total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=60; total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=60; total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=60; total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=60; total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=60; total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=60; total time=   5.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=60; total time=   5.3s\n"
     ]
    }
   ],
   "source": [
    "xgb_params = xgb_random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model best score 0.6067761324275728\n",
      "model best params {'n_estimators': 180, 'min_child_weight': 7, 'max_depth': 8, 'learning_rate': 0.2, 'gamma': 0.4, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "print(f\"model best score {xgb_params.best_score_}\")\n",
    "print(f\"model best params {xgb_params.best_params_}\")\n",
    "params = xgb_params.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
