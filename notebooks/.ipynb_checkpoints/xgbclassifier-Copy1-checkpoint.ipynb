{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer  \n",
    "from xgboost import XGBClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_raw_data(operating_system ='mac'):\n",
    "    '''generate a dictionary of raw dataframes\n",
    "    \n",
    "    parameters\n",
    "    -----------\n",
    "    type of operating system used windows or mac\n",
    "    default mac\n",
    "    \n",
    "    '''\n",
    "    if operating_system == 'mac':\n",
    "        base_file_path = r\"/Users/{}/Desktop/data\".format(os.getlogin())\n",
    "    if operating_system == 'windows':\n",
    "        base_file_path = r\"C:\\Users\\{}\\Desktop\\data\".format(os.getlogin())\n",
    "    df_dict = dict()\n",
    "    for file in os.listdir(base_file_path):\n",
    "        if file.endswith('.csv'):\n",
    "            df_dict[file.split('.')[0]] = pd.read_csv(os.path.join(base_file_path,file))\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = import_raw_data()\n",
    "df = df_dict.get('winemag-data-130k-v2').copy()\n",
    "temp_df = df_dict.get('temperature').copy()\n",
    "country_iso = df_dict.get('country_iso_data').copy()\n",
    "weather_month_v2 = df_dict.get('weather_country_month_v2').copy()\n",
    "features = df_dict.get('data_test').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119988, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.drop_duplicates(subset=['description','title'],inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='test', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAATEklEQVR4nO3df6zd9X3f8ecrdkhoagKUW0ZsNKPGakXRSskV8ZZuWkAxhmQBVSkCLcFLaVw1ZArapI7sH1aSaIm6NR1dGhUVN5C2UNaU4mYkrkXoqkwhcB1I+NWIO5oIuyR2MAGzqMkg7/1xPoZTcw2Xjznney/3+ZC+ut/v+/v5nvM+55/X/f4432+qCkmSerxq6AYkScuXISJJ6maISJK6GSKSpG6GiCSp2+qhG5i2E044odavXz90G5K0bOzateu7VTWz0LoVFyLr169nbm5u6DYkadlI8q3DrfNwliSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKnbivvFul7cmovXDN3CRBy44cDQLUivOBPdE0nyzST3JrknyVyrHZ9kZ5KH2t/jWj1Jrk4yn+TrSc4Ye50tbfxDSbaM1d/UXn++bZtJfh5J0j80jcNZb62q06tqti1fAdxWVRuA29oywLnAhjZtBT4Fo9ABrgTeDJwJXHkweNqY941tt3nyH0eSdNAQ50TOB65r89cBF4zVr6+RO4Bjk5wEnAPsrKr9VfU4sBPY3NYdU1V31OhB8dePvZYkaQomHSIF/GWSXUm2ttqJVfVom/82cGKbXws8Mrbt7lZ7ofruBerPk2Rrkrkkc/v27TuSzyNJGjPpE+u/UFV7kvwksDPJ34yvrKpKUhPugaq6BrgGYHZ2duLvJ0krxUT3RKpqT/u7F7iZ0TmN77RDUbS/e9vwPcDJY5uva7UXqq9boC5JmpKJhUiS1yVZc3Ae2ATcB2wHDl5htQW4pc1vBy5pV2ltBJ5oh712AJuSHNdOqG8CdrR1TybZ2K7KumTstSRJUzDJw1knAje3q25XA39cVV9IchdwU5JLgW8BF7bxtwLnAfPA94H3AlTV/iQfBu5q466qqv1t/v3Ap4Gjgc+3SZI0JRMLkap6GPi5BeqPAWcvUC/gssO81jZg2wL1OeC0I25WktTF255IkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6jbJJxtKy96ai9cM3cJEHLjhwNAt6BXCPRFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHWbeIgkWZXk7iSfa8unJPlKkvkkf5LkqFZ/TVueb+vXj73Gh1r9G0nOGatvbrX5JFdM+rNIkv6haeyJfBB4cGz548AnquqNwOPApa1+KfB4q3+ijSPJqcBFwM8Cm4HfbcG0CvgkcC5wKnBxGytJmpKJhkiSdcDbgd9vywHOAv60DbkOuKDNn9+WaevPbuPPB26sqh9U1d8C88CZbZqvqoer6ofAjW2sJGlKJr0n8tvArwM/ass/AXyvqp5uy7uBtW1+LfAIQFv/RBv/bP2QbQ5Xf54kW5PMJZnbt2/fEX4kSdJBEwuRJO8A9lbVrkm9x2JV1TVVNVtVszMzM0O3I0mvGKsn+NpvAd6Z5DzgtcAxwH8Djk2yuu1trAP2tPF7gJOB3UlWA68HHhurHzS+zeHqkqQpmNieSFV9qKrWVdV6RifGv1hV/xq4HXhXG7YFuKXNb2/LtPVfrKpq9Yva1VunABuAO4G7gA3taq+j2ntsn9TnkSQ93yT3RA7nPwA3JvkIcDdwbatfC3wmyTywn1EoUFX3J7kJeAB4Grisqp4BSPIBYAewCthWVfdP9ZNI0go3lRCpqr8C/qrNP8zoyqpDx/w98EuH2f6jwEcXqN8K3PoytipJegn8xbokqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6TSxEkrw2yZ1Jvpbk/iS/0eqnJPlKkvkkf5LkqFZ/TVueb+vXj73Wh1r9G0nOGatvbrX5JFdM6rNIkhY2yT2RHwBnVdXPAacDm5NsBD4OfKKq3gg8Dlzaxl8KPN7qn2jjSHIqcBHws8Bm4HeTrEqyCvgkcC5wKnBxGytJmpKJhUiNPNUWX92mAs4C/rTVrwMuaPPnt2Xa+rOTpNVvrKofVNXfAvPAmW2ar6qHq+qHwI1trCRpSiZ6TqTtMdwD7AV2Av8H+F5VPd2G7AbWtvm1wCMAbf0TwE+M1w/Z5nD1hfrYmmQuydy+fftehk8mSYIJh0hVPVNVpwPrGO05/Mwk3+8F+rimqmaranZmZmaIFiTpFWlRIZLktsXUDqeqvgfcDvxT4Ngkq9uqdcCeNr8HOLm99mrg9cBj4/VDtjlcXZI0JS8YIu0Kq+OBE5Icl+T4Nq3nMIeOxradSXJsmz8aeBvwIKMweVcbtgW4pc1vb8u09V+sqmr1i9rVW6cAG4A7gbuADe1qr6MYnXzfvviPLkk6UqtfZP2vApcDbwB2AWn1J4H//iLbngRc166iehVwU1V9LskDwI1JPgLcDVzbxl8LfCbJPLCfUShQVfcnuQl4AHgauKyqngFI8gFgB7AK2FZV9y/qU0uSXhYZ/bP/IoOSf1tVvzOFfiZudna25ubmhm5jSVtz8ZqhW5iIAzcceMnb+F1IkGRXVc0utO7F9kQAqKrfSfLPgPXj21TV9S9Lh5KkZWlRIZLkM8BPAfcAz7RyAYaIJK1giwoRYBY4tRZz7EuStGIs9nci9wH/aJKNSJKWn8XuiZwAPJDkTkb3xAKgqt45ka4kScvCYkPkP02yCUnS8rTYq7P+16QbkSQtP4u9OusAo6uxAI5idEfe/1tVx0yqMUnS0rfYPZFnf3E1dnv2jZNqSpK0PLzku/i254T8OXDOi42VJL2yLfZw1i+OLb6K0e9G/n4iHUmSlo3FXp31r8bmnwa+iU8RlKQVb7HnRN476UYkScvPYh9KtS7JzUn2tumzSdZNujlJ0tK22BPrf8DogU9vaNNftJokaQVbbIjMVNUfVNXTbfo04MPKJWmFW2yIPJbk3UlWtendjJ5/LklawRYbIr8MXAh8G3iU0TPQ/82EepIkLROLvcT3KmBLVT0OkOR44L8wChdJ0gq12D2Rf3IwQACqaj/w85NpSZK0XCw2RF6V5LiDC21PZLF7MZKkV6jFBsF/Bb6c5H+05V8CPjqZliRJy8Vif7F+fZI54KxW+sWqemBybUmSloNFH5JqoWFwSJKe9ZJvBS9J0kGGiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkrpNLESSnJzk9iQPJLk/yQdb/fgkO5M81P4e1+pJcnWS+SRfT3LG2GttaeMfSrJlrP6mJPe2ba5Okkl9HknS801yT+Rp4N9X1anARuCyJKcCVwC3VdUG4La2DHAusKFNW4FPwbM3e7wSeDNwJnDl2M0gPwW8b2y7zRP8PJKkQ0wsRKrq0ar6aps/ADwIrAXOB65rw64DLmjz5wPX18gdwLFJTgLOAXZW1f52O/qdwOa27piquqOqCrh+7LUkSVMwlXMiSdYzev7IV4ATq+rRturbwIltfi3wyNhmu1vtheq7F6gv9P5bk8wlmdu3b9+RfRhJ0rMmHiJJfhz4LHB5VT05vq7tQdSke6iqa6pqtqpmZ2ZmJv12krRiTDREkryaUYD8UVX9WSt/px2Kov3d2+p7gJPHNl/Xai9UX7dAXZI0JZO8OivAtcCDVfVbY6u2AwevsNoC3DJWv6RdpbUReKId9toBbEpyXDuhvgnY0dY9mWRje69Lxl5LkjQFk3zE7VuA9wD3Jrmn1f4j8DHgpiSXAt8CLmzrbgXOA+aB7wPvhdHz3JN8GLirjbuqPeMd4P3Ap4Gjgc+3SZI0JRMLkar6EnC4322cvcD4Ai47zGttA7YtUJ8DTjuCNiVJR8BfrEuSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuq4duYKlYc/GaoVuYiAM3HBi6BUmvYIaIpEXxHy0txMNZkqRuhogkqZshIknqNrEQSbItyd4k943Vjk+yM8lD7e9xrZ4kVyeZT/L1JGeMbbOljX8oyZax+puS3Nu2uTpJJvVZJEkLm+SeyKeBzYfUrgBuq6oNwG1tGeBcYEObtgKfglHoAFcCbwbOBK48GDxtzPvGtjv0vSRJEzaxEKmqvwb2H1I+H7iuzV8HXDBWv75G7gCOTXIScA6ws6r2V9XjwE5gc1t3TFXdUVUFXD/2WpKkKZn2OZETq+rRNv9t4MQ2vxZ4ZGzc7lZ7ofruBeoLSrI1yVySuX379h3ZJ5AkPWuwE+ttD6Km9F7XVNVsVc3OzMxM4y0laUWYdoh8px2Kov3d2+p7gJPHxq1rtReqr1ugLkmaommHyHbg4BVWW4BbxuqXtKu0NgJPtMNeO4BNSY5rJ9Q3ATvauieTbGxXZV0y9lqSpCmZ2G1PktwA/EvghCS7GV1l9THgpiSXAt8CLmzDbwXOA+aB7wPvBaiq/Uk+DNzVxl1VVQdP1r+f0RVgRwOfb5MkaYomFiJVdfFhVp29wNgCLjvM62wDti1QnwNOO5IeJUlHxl+sS5K6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqtuxDJMnmJN9IMp/kiqH7kaSVZPXQDRyJJKuATwJvA3YDdyXZXlUPDNuZpFeyNRevGbqFiThww4GXvM1y3xM5E5ivqoer6ofAjcD5A/ckSStGqmroHroleRewuap+pS2/B3hzVX3gkHFbga1t8aeBb0y10ec7AfjuwD0sFX4Xz/G7eI7fxXOWwnfxj6tqZqEVy/pw1mJV1TXANUP3cVCSuaqaHbqPpcDv4jl+F8/xu3jOUv8ulvvhrD3AyWPL61pNkjQFyz1E7gI2JDklyVHARcD2gXuSpBVjWR/Oqqqnk3wA2AGsArZV1f0Dt7UYS+bQ2hLgd/Ecv4vn+F08Z0l/F8v6xLokaVjL/XCWJGlAhogkqZshMkVJtiXZm+S+oXsZWpKTk9ye5IEk9yf54NA9DSXJa5PcmeRr7bv4jaF7GlKSVUnuTvK5oXsZWpJvJrk3yT1J5obuZyGeE5miJP8CeAq4vqpOG7qfISU5CTipqr6aZA2wC7hgJd6yJkmA11XVU0leDXwJ+GBV3TFwa4NI8u+AWeCYqnrH0P0MKck3gdmqGvrHhoflnsgUVdVfA/uH7mMpqKpHq+qrbf4A8CCwdtiuhlEjT7XFV7dpRf53l2Qd8Hbg94fuRYtjiGhwSdYDPw98ZeBWBtMO4dwD7AV2VtVK/S5+G/h14EcD97FUFPCXSXa12zctOYaIBpXkx4HPApdX1ZND9zOUqnqmqk5ndNeFM5OsuMOdSd4B7K2qXUP3soT8QlWdAZwLXNYOiS8phogG047/fxb4o6r6s6H7WQqq6nvA7cDmgVsZwluAd7bzADcCZyX5w2FbGlZV7Wl/9wI3M7pz+ZJiiGgQ7WTytcCDVfVbQ/czpCQzSY5t80czej7O3wza1ACq6kNVta6q1jO6hdEXq+rdA7c1mCSvaxedkOR1wCZgyV3ZaYhMUZIbgC8DP51kd5JLh+5pQG8B3sPov8172nTe0E0N5CTg9iRfZ3Q/uJ1VteIvbxUnAl9K8jXgTuB/VtUXBu7pebzEV5LUzT0RSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEmoIkxyZ5f+e2lyf5sZe7J+nlYIhI03Es0BUiwOWAIaIlaVk/Y11aRj4G/FS7yeJORjdavBB4DXBzVV3ZfpV8E6P7Z60CPszoB2dvYPRjxO9W1VuHaF46HENEmo4rgNOq6vQkm4B3MboPUoDt7cZ6M8DfVdXbAZK8vqqeaM/XeOtSfqaEVi4PZ0nTt6lNdwNfBX4G2ADcC7wtyceT/POqemLAHqVFcU9Emr4A/7mqfu95K5IzgPOAjyS5raqumnp30kvgnog0HQeANW1+B/DL7VkqJFmb5CeTvAH4flX9IfCbwBkLbCstKe6JSFNQVY8l+d9J7gM+D/wx8OXRHfF5Cng38EbgN5P8CPh/wK+1za8BvpDk7zyxrqXGu/hKkrp5OEuS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEnd/j9p2kSTs4Ts9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# changed from using original quantile list, big factor in driving results \n",
    "df['test'] = pd.cut(df['points'],bins=5,labels=[1,2,3,4,5])\n",
    "df['test'].value_counts()\n",
    "sns.countplot(x='test', color='darkgreen',\n",
    "                  data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**columns to remove**\n",
    "\n",
    "description, designation & Twitter handle removed at this stage, explore later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_DROP = ['Unnamed: 0','designation','region_2','taster_twitter_handle','points']\n",
    "df.drop(columns=COLUMN_DROP,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dealing with missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['variety','province','country','taster_name','region_1'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        0\n",
       "description    0\n",
       "price          0\n",
       "province       0\n",
       "region_1       0\n",
       "taster_name    0\n",
       "title          0\n",
       "variety        0\n",
       "winery         0\n",
       "test           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_median = SimpleImputer(strategy='median')\n",
    "df['price'] = imp_median.fit_transform(df[['price']])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['description','title'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing  & Feature Engineering\n",
    "\n",
    "extracting year from text and cleaing reuslt to produce valid year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## year \n",
    "count_year = df[df['title'].str.contains('\\d',regex=True)].shape[0]\n",
    "df['number_extract'] = df['title'].str.extract('(\\d+)')\n",
    "df['number_extract'] = np.where(len(df['number_extract'])<4 & len(df['number_extract'])<=5,np.nan,df['number_extract'])\n",
    "df['number_extract'] = pd.to_numeric(df['number_extract'])\n",
    "df['number_extract'] = np.where(\n",
    "                    (df['number_extract']>=2021) | (df['number_extract']<=(2021-70)),\n",
    "                    np.nan,\n",
    "                    df['number_extract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding simple imputer but may need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        0\n",
       "description    0\n",
       "price          0\n",
       "province       0\n",
       "region_1       0\n",
       "taster_name    0\n",
       "title          0\n",
       "variety        0\n",
       "winery         0\n",
       "test           0\n",
       "year           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_median = SimpleImputer(strategy='median')\n",
    "df['number_extract'] = imp_median.fit_transform(df[['number_extract']])\n",
    "df['number_extract'] = pd.to_datetime(df['number_extract'],format='%Y').dt.year \n",
    "df.rename(columns={'number_extract':'year'},inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating length of the name to work out whether name longer names and titles relate to better reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['title','taster_name']:\n",
    "     df[f\"{col}_length\"] = df[col].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO change labels to numbers\n",
    "df['price_bin'] = pd.cut(df['price'],bins=15,labels=False)\n",
    "df.drop(columns=['taster_name', 'title'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Weather Data\n",
    "\n",
    "additional feature related to average temperature for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_feature = df.set_index('country').join(country_iso.set_index('country'))\n",
    "weather_iso_df = weather_month_v2.set_index('country').join(country_iso.set_index('country'))\n",
    "weather_iso_df['year'] = pd.to_datetime(weather_iso_df['month']).dt.year\n",
    "weather_iso_summary_df = weather_iso_df.groupby(['country_iso', 'year'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "              weather_feature, \n",
    "              weather_iso_summary_df,  \n",
    "              how='left', \n",
    "              left_on=['country_iso','year'], \n",
    "              right_on=['country_iso','year']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description           0\n",
       "price                 0\n",
       "province              0\n",
       "region_1              0\n",
       "variety               0\n",
       "winery                0\n",
       "test                  0\n",
       "year                  0\n",
       "title_length          0\n",
       "taster_name_length    0\n",
       "price_bin             0\n",
       "country_iso           0\n",
       "avg_temp              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_median = SimpleImputer(strategy='median')\n",
    "df['avg_temp'] = imp_median.fit_transform(df[['avg_temp']])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_richness(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    return unique_word_length/total_length\n",
    "\n",
    "df['vocab richness'] = df['description'].apply(vocab_richness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/edwardburroughes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "punc = set(string.punctuation)\n",
    "\n",
    "#loading stop_words\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# creating a set of stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# combining the 2 sets with an \"or\" operator (i.e. \"|\")\n",
    "all_stops = stop_words | punc\n",
    "\n",
    "# loop to pre-process data\n",
    "clean_desc =[]\n",
    "for item in df['description'].to_list():\n",
    "    tok_desc = word_tokenize(item)\n",
    "    lower_data = [i.lower() for i in tok_desc]\n",
    "    tok_desc_no_num = [i for i in lower_data if i.isalpha()]\n",
    "    filtered_desc = [i for i in tok_desc_no_num if i not in all_stops]\n",
    "    clean_desc.append(filtered_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing the data in a new dataframe\n",
    "clean_desc_untok = [' '.join(i) for i in clean_desc]\n",
    "column_names = ['original_desc', 'untok_description']\n",
    "data_tuple= list(zip(df['description'], clean_desc_untok))\n",
    "desc_df = pd.DataFrame(data_tuple, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/edwardburroughes/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('movie_reviews')\n",
    "tb = Blobber(analyzer=NaiveBayesAnalyzer())\n",
    "blob = [tb(text) for text in desc_df['untok_description']]\n",
    "sentiment_values = [text.sentiment for text in blob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>0.0774711</td>\n",
       "      <td>0.922529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.835127</td>\n",
       "      <td>0.164873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.995154</td>\n",
       "      <td>0.00484628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>0.0718264</td>\n",
       "      <td>0.928174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.947882</td>\n",
       "      <td>0.0521175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clf        pos         neg\n",
       "0  neg  0.0774711    0.922529\n",
       "1  pos   0.835127    0.164873\n",
       "2  pos   0.995154  0.00484628\n",
       "3  neg  0.0718264    0.928174\n",
       "4  pos   0.947882   0.0521175"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.DataFrame(zip(*sentiment_values)).T\n",
    "stats.columns = ['clf','pos','neg']\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['clf', 'pos', 'neg'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-022a7c5e2f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6813\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6814\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 6815\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   6816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6817\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6828\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   6829\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6830\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   6831\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6832\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     46\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                          validate=validate)\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         llabels, rlabels = items_overlap_with_suffix(ldata.items, lsuf,\n\u001b[0;32m--> 552\u001b[0;31m                                                      rdata.items, rsuf)\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mlindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mleft_indexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mitems_overlap_with_suffix\u001b[0;34m(left, lsuffix, right, rsuffix)\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m             raise ValueError('columns overlap but no suffix specified: '\n\u001b[0;32m-> 1972\u001b[0;31m                              '{rename}'.format(rename=to_rename))\n\u001b[0m\u001b[1;32m   1973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['clf', 'pos', 'neg'], dtype='object')"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(stats['clf'])\n",
    "df = df.join(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move back onto original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['test','description','clf'])\n",
    "y = df[['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 0 to 19999\n",
      "Columns: 12629 entries, pos to 5_Zonda Valley\n",
      "dtypes: float64(5), int64(4), uint8(12620)\n",
      "memory usage: 242.2 MB\n"
     ]
    }
   ],
   "source": [
    "X[['pos','neg']] = X[['pos','neg']].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Feature selection defining best & worst features for one hot encoded categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1(model,X_test,y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_test,y_pred,average='weighted')\n",
    "    return score\n",
    "\n",
    "def create_dummies_ohe(X,cat_columns):\n",
    "    categorical_x = pd.get_dummies(X[cat_columns],prefix=['1','2','3','4','5'])\n",
    "    numeric_cols = list(set(X.columns)-set(cat_columns))\n",
    "    return pd.concat([X[numeric_cols],categorical_x], axis=1)\n",
    "\n",
    "def create_dummies_le(X,cat_columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in cat_columns:\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout method on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the features selected above\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "numeric_features = ['price','title_length','taster_name_length','avg_temp','year','pos','neg']\n",
    "cat_features = ['province','variety','country_iso','price_bin','winery','region_1']\n",
    "\n",
    "def select_cat_data_threshold(X,feature_data,threshold_value,cat_features=cat_features):\n",
    "    dictionary_filter = {cat:feature_data.loc[(feature_data[cat]==True) & \n",
    "                                              (feature_data['scores']<=threshold_value),'features']for cat in cat_features}\n",
    "    for cat,series in dictionary_filter.items():\n",
    "        X.loc[X[cat].isin(series),cat] = 'Other'\n",
    "    return (X,dictionary_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test whether the model speed and F1 given the threshold defined above and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import datetime\n",
    "X,features_replace = select_cat_data_threshold(X,features,1E-6)\n",
    "X = create_dummies_ohe(X,cat_features)\n",
    "X = X.iloc[:20000,:]\n",
    "y = y.iloc[:20000,:]\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "sc = QuantileTransformer()\n",
    "X_train[numeric_features] = sc.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = sc.fit_transform(X_test[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6130048100238207\n",
      "0:02:10.459613\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=500,n_jobs=-1)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(f1_score(y_test,y_pred,average='weighted'))\n",
    "end = datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8cd5bcc6d112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxgb_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multi:softmax'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mxgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    822\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1368\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "print('start model')\n",
    "xgb_classifier = XGBClassifier(objective='multi:softmax',n_estimators=500)\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "print(f1_score(y_test,y_pred,average='weighted'))\n",
    "print('end_model')\n",
    "end = datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using F1-score as imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using xgboost is almost is definitely better still very low lets amend the imbalances in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE,BorderlineSMOTE,SVMSMOTE\n",
    "from sklearn import neighbors\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "over = SMOTE()\n",
    "under = RandomUnderSampler()\n",
    "steps = [('o', over), ('u', under)]\n",
    "smote_pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversample = BorderlineSMOTE(sampling_strategy='minority',k_neighbors=1,m_neighbors=1)\n",
    "X_train_resample,y_train_resample = over.fit_resample(X_train,y_train)\n",
    "rf_classifier.fit(X_train_resample,y_train_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5346809977976993"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(rf_classifier,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smote perhaps a more focused sampling strategy is required for balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline = Pipeline([('o', oversample),\n",
    "           ('rf',RandomForestClassifier(n_estimators=500,n_jobs=-1))])\n",
    "parameters = {'o__sampling_strategy':('minority','not majority','all'),\n",
    "             'o__k_neighbors':[1,5],\n",
    "             'o__m_neighbors':[1,20]}\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, \n",
    "                           verbose=5, scoring = \"f1_weighted\", \n",
    "                           refit=True, cv=5)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o__k_neighbors': 1, 'o__m_neighbors': 20, 'o__sampling_strategy': 'minority'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {\"learning_rate\":[0.05,0.1,0.15,0.2,0.25,0.3,0.35],\n",
    "          \"max_depth\":[3,4,5,6,8,10,12,15,17],\n",
    "          \"min_child_weight\":[1,3,5,7,9,11],\n",
    "          \"gamma\":[0.0,0.1,0.3,0.4,0.5,0.6],\n",
    "          \"colsample_bytree\":[0.3,0.4,0.5,0.7,0.8,0.9],\n",
    "          \"n_estimators\":range(60, 220, 40)\n",
    "         }\n",
    "xgb_random_search = RandomizedSearchCV(xgb_classifier,\n",
    "                                       param_distributions=params,\n",
    "                                       cv=5,\n",
    "                                       scoring='f1_weighted',\n",
    "                                       verbose=3,\n",
    "                                       n_iter = 10,\n",
    "                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=15, min_child_weight=1, n_estimators=180; total time=  35.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=15, min_child_weight=1, n_estimators=180; total time=  37.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=15, min_child_weight=1, n_estimators=180; total time=  37.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=15, min_child_weight=1, n_estimators=180; total time=  40.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=15, min_child_weight=1, n_estimators=180; total time=  37.4s\n",
      "[CV 1/5] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=6, min_child_weight=3, n_estimators=60; total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=6, min_child_weight=3, n_estimators=60; total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=6, min_child_weight=3, n_estimators=60; total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=6, min_child_weight=3, n_estimators=60; total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=6, min_child_weight=3, n_estimators=60; total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=60; total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=60; total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=60; total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=60; total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=60; total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=8, min_child_weight=7, n_estimators=180; total time=  20.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=8, min_child_weight=7, n_estimators=180; total time=  21.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=8, min_child_weight=7, n_estimators=180; total time=  21.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=8, min_child_weight=7, n_estimators=180; total time=  20.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=8, min_child_weight=7, n_estimators=180; total time=  20.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, min_child_weight=9, n_estimators=100; total time=  18.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, min_child_weight=9, n_estimators=100; total time=  19.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, min_child_weight=9, n_estimators=100; total time=  18.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, min_child_weight=9, n_estimators=100; total time=  18.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, min_child_weight=9, n_estimators=100; total time=  18.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=180; total time=  16.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=180; total time=  17.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=180; total time=  16.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=180; total time=  16.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=180; total time=  16.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.6, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100; total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.6, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100; total time=   3.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.6, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100; total time=   4.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.6, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100; total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.6, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100; total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.15, max_depth=17, min_child_weight=7, n_estimators=180; total time=  44.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.15, max_depth=17, min_child_weight=7, n_estimators=180; total time=  45.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.15, max_depth=17, min_child_weight=7, n_estimators=180; total time=  43.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.15, max_depth=17, min_child_weight=7, n_estimators=180; total time=  43.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.15, max_depth=17, min_child_weight=7, n_estimators=180; total time=  45.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=60; total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=60; total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=60; total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=60; total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=60; total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=60; total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=60; total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=60; total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=60; total time=   5.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=60; total time=   5.3s\n"
     ]
    }
   ],
   "source": [
    "xgb_params = xgb_random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model best score 0.6067761324275728\n",
      "model best params {'n_estimators': 180, 'min_child_weight': 7, 'max_depth': 8, 'learning_rate': 0.2, 'gamma': 0.4, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "print(f\"model best score {xgb_params.best_score_}\")\n",
    "print(f\"model best params {xgb_params.best_params_}\")\n",
    "params = xgb_params.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "test = pd.Series([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
